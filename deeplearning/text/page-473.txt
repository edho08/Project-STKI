CHAPTER 12. APPLICATIONS

12.2.1.2 Dataset Augmentation
As described in section 7.4, it is easy to improve the generalization of a classifier by increasing the size of the training set by adding extra copies of the training examples that have been modified with transformations that do not change the class. Object recognition is a classification task that is especially amenable to this form of dataset augmentation because the class is invariant to so many transformations and the input can be easily transformed with many geometric operations. As described before, classifiers can benefit from random translations, rotations, and in some cases, flips of the input to augment the dataset. In specialized computer vision applications, more advanced transformations are commonly used for dataset augmentation. These schemes include random perturbation of the colors in an image (Krizhevsky et al., 2012) and nonlinear geometric distortions of the input (LeCun et al., 1998b).

12.3 Speech Recognition

The task of speech recognition is to map an acoustic signal containing a spoken
natural language utterance into the corresponding sequence of words intended by the speaker. Let X = (x(1), x(2), . . . , x(T )) denote the sequence of acoustic input
vectors (traditionally produced by splitting the audio into 20ms frames). Most
speech recognition systems preprocess the input using specialized hand-designed
features, but some (Jaitly and Hinton, 2011) deep learning systems learn features
from raw input. Let y = (y1 , y2, . . . , yN ) denote the target output sequence (usually a sequence of words or characters). The automatic speech recognition (ASR) task consists of creating a function fASR that computes the most probable linguistic sequence y given the acoustic sequence X:

fASR(X) = arg max P (y | X = X)
y

(12.4)

where P  is the true conditional distribution relating the inputs X to the targets y.

Since the 1980s and until about 2009­2012, state-of-the art speech recognition systems primarily combined hidden Markov models (HMMs) and Gaussian mixture models (GMMs). GMMs modeled the association between acoustic features and phonemes (Bahl et al., 1987), while HMMs modeled the sequence of phonemes. The GMM-HMM model family treats acoustic waveforms as being generated by the following process: first an HMM generates a sequence of phonemes and discrete sub-phonemic states (such as the beginning, middle, and end of each

458

