CHAPTER 7. REGULARIZATION FOR DEEP LEARNING
of the data. In this second training pass, we train for the same number of steps as the early stopping procedure determined was optimal in the first pass. There are some subtleties associated with this procedure. For example, there is not a good way of knowing whether to retrain for the same number of parameter updates or the same number of passes through the dataset. On the second round of training, each pass through the dataset will require more parameter updates because the training set is bigger.
Algorithm 7.2 A meta-algorithm for using early stopping to determine how long to train, then retraining on all the data.
Let X(train) and y(train) be the training set. Split X(train) and y(train) into (X(subtrain) , X (valid)) and (y(subtrain) , y(valid)) respectively. Run early stopping (algorithm 7.1) starting from random  using X(subtrain) and y(subtrain) for training data and X(valid) and y(valid) for validation data. This returns i, the optimal number of steps. Set  to random values again. Train on X (train) and y(train) for i steps.
Another strategy for using all of the data is to keep the parameters obtained from the first round of training and then continue training but now using all of the data. At this stage, we now no longer have a guide for when to stop in terms of a number of steps. Instead, we can monitor the average loss function on the validation set, and continue training until it falls below the value of the training set objective at which the early stopping procedure halted. This strategy avoids the high cost of retraining the model from scratch, but is not as well-behaved. For example, there is not any guarantee that the objective on the validation set will ever reach the target value, so this strategy is not even guaranteed to terminate. This procedure is presented more formally in algorithm 7.3.
Early stopping is also useful because it reduces the computational cost of the training procedure. Besides the obvious reduction in cost due to limiting the number of training iterations, it also has the benefit of providing regularization without requiring the addition of penalty terms to the cost function or the computation of the gradients of such additional terms.
How early stopping acts as a regularizer: So far we have stated that early stopping is a regularization strategy, but we have supported this claim only by showing learning curves where the validation set error has a U-shaped curve. What
249

