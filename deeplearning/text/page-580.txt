CHAPTER 16. STRUCTURED PROBABILISTIC MODELS FOR DEEP LEARNING
redundant by the constraint that the sum of the probabilities be 1). If instead, we only make a table for each of the conditional probability distributions, then the distribution over t0 requires 99 values, the table defining t1 given t0 requires 9900 values, and so does the table defining t2 given t1. This comes to a total of 19,899 values. This means that using the directed graphical model reduced our number of parameters by a factor of more than 50!
In general, to model n discrete variables each having k values, the cost of the single table approach scales like O(k n), as we have observed before. Now suppose we build a directed graphical model over these variables. If m is the maximum number of variables appearing (on either side of the conditioning bar) in a single conditional probability distribution, then the cost of the tables for the directed model scales like O( km). As long as we can design a model such that m << n, we get very dramatic savings.
In other words, so long as each variable has few parents in the graph, the distribution can be represented with very few parameters. Some restrictions on the graph structure, such as requiring it to be a tree, can also guarantee that operations like computing marginal or conditional distributions over subsets of variables are efficient.
It is important to realize what kinds of information can and cannot be encoded in the graph. The graph encodes only simplifying assumptions about which variables are conditionally independent from each other. It is also possible to make other kinds of simplifying assumptions. For example, suppose we assume Bob always runs the same regardless of how Alice performed. (In reality, Alice's performance probably influences Bob's performance--depending on Bob's personality, if Alice runs especially fast in a given race, this might encourage Bob to push hard and match her exceptional performance, or it might make him overconfident and lazy). Then the only effect Alice has on Bob's finishing time is that we must add Alice's finishing time to the total amount of time we think Bob needs to run. This observation allows us to define a model with O(k) parameters instead of O(k 2). However, note that t0 and t1 are still directly dependent with this assumption, because t1 represents the absolute time at which Bob finishes, not the total time he himself spends running. This means our graph must still contain an arrow from t0 to t1. The assumption that Bob's personal running time is independent from all other factors cannot be encoded in a graph over t0, t1, and t2 . Instead, we encode this information in the definition of the conditional distribution itself. The conditional distribution is no longer a k × k - 1 element table indexed by t0 and t1 but is now a slightly more complicated formula using only k - 1 parameters. The directed graphical model syntax does not place any constraint on how we define
565

