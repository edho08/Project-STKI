CHAPTER 5. MACHINE LEARNING BASICS

The variance or the standard error of an estimator provides a measure of how we would expect the estimate we compute from data to vary as we independently resample the dataset from the underlying data generating process. Just as we might like an estimator to exhibit low bias we would also like it to have relatively low variance.

When we compute any statistic using a finite number of samples, our estimate of the true underlying parameter is uncertain, in the sense that we could have obtained other samples from the same distribution and their statistics would have been different. The expected degree of variation in any estimator is a source of error that we want to quantify.

The standard error of the mean is given by

SE(µ^m) =

   Var



1 m

 m

 x(i)

=

 m

,

i=1

(5.46)

where 2 is the true variance of the samples xi. The standard error is often estimated by using an estimate of . Unfortunately, neither the square root of the sample variance nor the square root of the unbiased estimator of the variance provide an unbiased estimate of the standard deviation. Both approaches tend to underestimate the true standard deviation, but are still used in practice. The square root of the unbiased estimator of the variance is less of an underestimate. For large m, the approximation is quite reasonable.

The standard error of the mean is very useful in machine learning experiments.

We often estimate the generalization error by computing the sample mean of the

error on the test set. The number of examples in the test set determines the

accuracy of this estimate. Taking advantage of the central limit theorem, which

tells us that the mean will be approximately distributed with a normal distribution,

we can use the standard error to compute the probability that the true expectation

falls in any chosen interval. For example, the 95% confidence interval centered on

the mean µ^ m is

(µ^m - 1.96SE(µ^ m), µ^m + 1.96SE(µ^m)),

(5.47)

under the normal distribution with mean µ^m and variance SE(µ^m)2 . In machine learning experiments, it is common to say that algorithm A is better than algorithm B if the upper bound of the 95% confidence interval for the error of algorithm A is less than the lower bound of the 95% confidence interval for the error of algorithm B.

128

