CHAPTER 17. MONTE CARLO METHODS
distribution) in section 18.7, and to estimate the log-likelihood in deep directed models such as the variational autoencoder, in section 20.10.3. Importance sampling may also be used to improve the estimate of the gradient of the cost function used to train model parameters with stochastic gradient descent, particularly for models such as classifiers where most of the total value of the cost function comes from a small number of misclassified examples. Sampling more difficult examples more frequently can reduce the variance of the gradient in such cases (Hinton, 2006).
17.3 Markov Chain Monte Carlo Methods
In many cases, we wish to use a Monte Carlo technique but there is no tractable method for drawing exact samples from the distribution pmodel(x) or from a good (low variance) importance sampling distribution q (x). In the context of deep learning, this most often happens when pmodel(x) is represented by an undirected model. In these cases, we introduce a mathematical tool called a Markov chain to approximately sample from pmodel (x). The family of algorithms that use Markov chains to perform Monte Carlo estimates is called Markov chain Monte Carlo methods (MCMC). Markov chain Monte Carlo methods for machine learning are described at greater length in Koller and Friedman (2009). The most standard, generic guarantees for MCMC techniques are only applicable when the model does not assign zero probability to any state. Therefore, it is most convenient to present these techniques as sampling from an energy-based model (EBM) p(x)  exp (-E(x)) as described in section 16.2.4. In the EBM formulation, every state is guaranteed to have non-zero probability. MCMC methods are in fact more broadly applicable and can be used with many probability distributions that contain zero probability states. However, the theoretical guarantees concerning the behavior of MCMC methods must be proven on a case-by-case basis for different families of such distributions. In the context of deep learning, it is most common to rely on the most general theoretical guarantees that naturally apply to all energy-based models.
To understand why drawing samples from an energy-based model is difficult, consider an EBM over just two variables, defining a distribution p(a, b). In order to sample a, we must draw a from p(a | b), and in order to sample b, we must draw it from p(b | a). It seems to be an intractable chicken-and-egg problem. Directed models avoid this because their graph is directed and acyclic. To perform ancestral sampling one simply samples each of the variables in topological order, conditioning on each variable's parents, which are guaranteed to have already been sampled (section 16.3). Ancestral sampling defines an efficient, single-pass method
595

