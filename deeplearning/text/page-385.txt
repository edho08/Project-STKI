CHAPTER 9. CONVOLUTIONAL NETWORKS
Figure 9.18: Gabor functions with a variety of parameter settings. White indicates large positive weight, black indicates large negative weight, and the background gray corresponds to zero weight. (Left)Gabor functions with different values of the parameters that control the coordinate system: x0, y0, and  . Each Gabor function in this grid is assigned a value of x0 and y0 proportional to its position in its grid, and  is chosen so that each Gabor filter is sensitive to the direction radiating out from the center of the grid. For the other two plots, x0, y0, and  are fixed to zero. (Center)Gabor functions with different Gaussian scale parameters x and y. Gabor functions are arranged in increasing width (decreasing x) as we move left to right through the grid, and increasing height (decreasing y) as we move top to bottom. For the other two plots, the  values are fixed to 1.5× the image width. (Right)Gabor functions with different sinusoid parameters f and . As we move top to bottom, f increases, and as we move left to right,  increases. For the other two plots,  is fixed to 0 and f is fixed to 5× the image width.
(replacing black with white and vice versa). Some of the most striking correspondences between neuroscience and machine
learning come from visually comparing the features learned by machine learning models with those employed by V1. Olshausen and Field (1996) showed that a simple unsupervised learning algorithm, sparse coding, learns features with receptive fields similar to those of simple cells. Since then, we have found that an extremely wide variety of statistical learning algorithms learn features with Gabor-like functions when applied to natural images. This includes most deep learning algorithms, which learn these features in their first layer. Figure 9.19 shows some examples. Because so many different learning algorithms learn edge detectors, it is difficult to conclude that any specific learning algorithm is the "right" model of the brain just based on the features that it learns (though it can certainly be a bad sign if an algorithm does not learn some sort of edge detector when applied to natural images). These features are an important part of the statistical structure of natural images and can be recovered by many different approaches to statistical modeling. See Hyvärinen et al. (2009) for a review of the field of natural image statistics.
370

